---
services:
  adguard-home-mcp:
    image: docker.io/knucklessg1/adguard-home-mcp:latest
    # build: . # Debug
    container_name: adguard-home-mcp
    hostname: adguard-home-mcp
    command: [ "adguard-home-mcp" ]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=8012"
      - "TRANSPORT=streamable-http"
      - "ADGUARD_URL=${ADGUARD_URL}"
      - "ADGUARD_USERNAME=${ADGUARD_USERNAME}"
      - "ADGUARD_PASSWORD=${ADGUARD_PASSWORD}"
    ports:
      - "8012:8012"
    healthcheck:
      test: [ "CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8012/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  adguard-home-agent:
    image: docker.io/knucklessg1/adguard-home-mcp:latest
    # build: . # Debug
    container_name: adguard-home-agent
    hostname: adguard-home-agent
    command: [ "adguard-home-agent" ]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - adguard-home-mcp
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=9012"
      - "MCP_URL=http://adguard-home-mcp:8012/mcp"
      - "PROVIDER=openai"
      - "LLM_BASE_URL=http://host.docker.internal:1234/v1"
      - "LLM_API_KEY=llama"
      - "MODEL_ID=${MODEL_ID:-qwen/qwen3-coder-next}"
      - "DEBUG=False"
      - "ENABLE_WEB_UI=True"
    ports:
      - "9012:9012"
    healthcheck:
      test: [ "CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9012/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
